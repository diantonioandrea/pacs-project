\subsection{\textit{h-Adaptivity}}

\begin{frame}
    \frametitle{\textit{h-Adaptivity}}

    The need for \textit{h-adaptivity} arises from the inefficiency encountered when solving the Poisson problem over sequences of uniform meshes, especially when dealing with low-regularity exact solutions.

    To implement \textit{h-adaptivity}, the first step is to evaluate the $\LT$ error on each element and then refine the element with the highest error according to a specific refinement strategy.    

\end{frame}

\begin{frame}
    \frametitle{Refinement strategy}

    \begin{enumerate}
        \item For polygons with $N_e \leq 4$, the refiner adds a single node at the polygon's centroid.
        \item For polygons with $N_e > 4$, the refiner adds $N_e$ new nodes at the midpoints of the segments connecting the polygon's centroid to the midpoints of its edges.
    \end{enumerate}

    The elements $K$ to be refined are chosen in the following way:

    \begin{gather}
        \eta_K > \sigma \eta_{M},
    \end{gather}

\end{frame}

\begin{frame}
    \frametitle{\textit{A posteriori} error estimator}

    The second step in implementing \textit{h-adaptivity} is to define an \textit{a posteriori} error estimator, which enables the identification of elements that need refinement without requiring any information about the exact solution.

    One possible approach considers the following upper bound on the error:

    \begin{gather}
        \lVert u - u^k_h \rVert_{\LT(\Omega)} \leq C_{ub} \sum_{K \in \Tau_h} (R_K^2 + O_K^2),
    \end{gather}

    where $R_K^2 = R_{K, E}^2 + R_{K, N}^2 + R_{K, J}^2 + R_{K, T}^2$ is the local estimator and $O_K^2 = O_{K, E}^2 + O_{K, J}^2 + O_{K, T}^2$ is the local data oscillation.

\end{frame}

\begin{frame}
    \frametitle{\textit{A posteriori} error estimator}

    Each term is given by:

    \begin{align}
        R_{K, E} &= \lVert h (\bar{f} + \Delta u^k_h) \rVert_{\LT(K)},\notag \\
        R_{K, N} &= \lVert h^{1/2} \llbracket \grad u^k_h \cdot \Vector{n} \rrbracket \rVert_{\LT(\partial K)},\notag \\
        R^2_{K, J} &= \lVert \gamma^{1/2} \llbracket u^k_h \rrbracket \rVert^2_{\LT(\partial K \cap \Gamma_{i})} + \lVert \gamma^{1/2} (u^k_h - \bar{g}) \rVert^2_{\LT(\partial K \cap \partial \Omega)},\notag \\
        R^2_{K, T} &= \lVert h^{1/2} \llbracket \grad u^k_h \cdot \Vector{e} \rrbracket \rVert^2_{\LT(\partial K \cap \Gamma_{i})} + \lVert \gamma^{1/2} \grad (u^k_h - \bar{g}) \cdot \Vector{e} \rVert^2_{\LT(\partial K \cap \partial \Omega)},\notag \\
        O_{K, E} &= \lVert h (f - \bar{f}) \rVert_{\LT(K)},\notag \\
        O_{K, J} &= \lVert \gamma^{1/2} (g - \bar{g}) \rVert_{\LT(\partial K \cap \partial \Omega)},\notag \\
        O_{K, T} &= \lVert h^{1/2} \grad (g - \bar{g}) \cdot \Vector{e} \rVert_{\LT(\partial K \cap \partial \Omega)}. \notag
    \end{align}

\end{frame}

\subsection{\textit{hp-Adaptivity}}

\begin{frame}
    \frametitle{\textit{hp-Adaptivity}}

    The next and final step is to implement \textit{p-adaptive} refinement using a test of analyticity.

    Since the solution is represented by the coefficients of Legendre polynomials, analyticity can be assessed by evaluating their rate of decay. Assuming smoothness for $u^k_{h, K}$, the following holds:

    \begin{gather}
        \Exists a_K, b_K \in \R : c_{ij} \approx a_K e^{-b_K (i + j)}.
    \end{gather}

    The elements $K$ to be refined are chosen in the following way:

    \begin{gather}
        \eta_K^2 > \sigma \bar{\eta}^2,
    \end{gather}

    The value of $b_K$ lets us decide whether to \textit{h-refine} or \textit{p-refine} an element.

\end{frame}